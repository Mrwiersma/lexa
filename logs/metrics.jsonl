{"step": 0, "dataset_size": 75.0, "train/return": -152.19944512844086, "train/length": 75.0, "train/episodes": 1.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.140902519226074, "train/max_reward/goal_0": -2.4463798999786377, "train/mean_reward/goal_0": -2.872290451275675, "train/final_reward/goal_0": -2.804420232772827, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.10526315789473684, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.71290922164917, "train/max_reward/goal_1": -0.20922215282917023, "train/mean_reward/goal_1": -1.8998635672032833, "train/final_reward/goal_1": -2.6192004680633545, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.140902519226074, "train/max_reward/goal_2": -2.4463798999786377, "train/mean_reward/goal_2": -2.872290451275675, "train/final_reward/goal_2": -2.804420232772827, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.266805410385132, "train/max_reward/goal_3": -1.3181289434432983, "train/mean_reward/goal_3": -1.8252263461288654, "train/final_reward/goal_3": -1.9087649583816528, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.322442054748535, "train/max_reward/goal_4": -1.0042475461959839, "train/mean_reward/goal_4": -1.6624786602823358, "train/final_reward/goal_4": -1.549200415611267, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -1.9268054962158203, "train/max_reward/goal_5": -1.165736436843872, "train/mean_reward/goal_5": -1.4845206988485236, "train/final_reward/goal_5": -1.5687649250030518, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.7168054580688477, "train/max_reward/goal_6": -1.7331287860870361, "train/mean_reward/goal_6": -2.2264627030021265, "train/final_reward/goal_6": -2.358764886856079, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.066805362701416, "train/max_reward/goal_7": -2.0831286907196045, "train/mean_reward/goal_7": -2.6266396484876933, "train/final_reward/goal_7": -2.7087650299072266, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.8000564575195312, "train/max_reward/goal_8": -1.8774681091308594, "train/mean_reward/goal_8": -2.3189781449343028, "train/final_reward/goal_8": -2.1744203567504883, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.266805410385132, "train/max_reward/goal_9": -1.3181289434432983, "train/mean_reward/goal_9": -1.8111144225848348, "train/final_reward/goal_9": -1.9087649583816528, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.000056505203247, "train/max_reward/goal_10": -1.0163798332214355, "train/mean_reward/goal_10": -1.5575118551128788, "train/final_reward/goal_10": -1.6192004680633545, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.71290922164917, "train/max_reward/goal_11": -0.9299659729003906, "train/mean_reward/goal_11": -2.017952688430485, "train/final_reward/goal_11": -2.6192004680633545}
{"step": 0, "dataset_size": 150.0, "train/return": -113.52061134576797, "train/length": 75.0, "train/episodes": 2.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.14042067527771, "train/max_reward/goal_0": -1.4772472381591797, "train/mean_reward/goal_0": -2.723539855919386, "train/final_reward/goal_0": -2.4688520431518555, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.3157894736842105, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.722423553466797, "train/max_reward/goal_1": -0.16350151598453522, "train/mean_reward/goal_1": -1.4069863663692224, "train/final_reward/goal_1": -2.4364492893218994, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.14042067527771, "train/max_reward/goal_2": -1.2400000095367432, "train/mean_reward/goal_2": -2.720203763560245, "train/final_reward/goal_2": -2.4688520431518555, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -3.1227707862854004, "train/max_reward/goal_3": -1.4970180988311768, "train/mean_reward/goal_3": -2.0880554773305593, "train/final_reward/goal_3": -2.244333267211914, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.573301076889038, "train/max_reward/goal_4": -0.9920669198036194, "train/mean_reward/goal_4": -1.7459514886140823, "train/final_reward/goal_4": -1.767782211303711, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -3.133301258087158, "train/max_reward/goal_5": -1.1186274290084839, "train/mean_reward/goal_5": -1.7653600855877525, "train/final_reward/goal_5": -1.9043333530426025, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -3.1324589252471924, "train/max_reward/goal_6": -1.699524998664856, "train/mean_reward/goal_6": -2.3759337475425317, "train/final_reward/goal_6": -2.69433331489563, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.092007637023926, "train/max_reward/goal_7": -2.0098841190338135, "train/mean_reward/goal_7": -2.549271119268317, "train/final_reward/goal_7": -3.0443334579467773, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.833660364151001, "train/max_reward/goal_8": -1.1466113328933716, "train/mean_reward/goal_8": -2.1950447935807076, "train/final_reward/goal_8": -2.0974628925323486, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -3.1227707862854004, "train/max_reward/goal_9": -1.4066128730773926, "train/mean_reward/goal_9": -2.0723286490691337, "train/final_reward/goal_9": -2.244333267211914, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.033660411834717, "train/max_reward/goal_10": -0.8889598846435547, "train/mean_reward/goal_10": -1.5068501492864208, "train/final_reward/goal_10": -1.4364492893218994, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.722423553466797, "train/max_reward/goal_11": -0.7441185712814331, "train/mean_reward/goal_11": -1.7762496934125298, "train/final_reward/goal_11": -2.4364492893218994}
{"step": 0, "dataset_size": 225.0, "train/return": -141.39642268419266, "train/length": 75.0, "train/episodes": 3.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.1412785053253174, "train/max_reward/goal_0": -1.8892152309417725, "train/mean_reward/goal_0": -2.907062088188372, "train/final_reward/goal_0": -2.9894630908966064, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.06578947368421052, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.6992759704589844, "train/max_reward/goal_1": -0.37435096502304077, "train/mean_reward/goal_1": -2.1189331510349323, "train/final_reward/goal_1": -2.471700429916382, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.1412785053253174, "train/max_reward/goal_2": -1.8892152309417725, "train/mean_reward/goal_2": -2.907062088188372, "train/final_reward/goal_2": -2.9894630908966064, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.823970079421997, "train/max_reward/goal_3": -1.419463038444519, "train/mean_reward/goal_3": -1.8013451162137484, "train/final_reward/goal_3": -1.419463038444519, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.566176652908325, "train/max_reward/goal_4": -0.9183831810951233, "train/mean_reward/goal_4": -1.8857946419402172, "train/final_reward/goal_4": -1.9729468822479248, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.4839701652526855, "train/max_reward/goal_5": -1.1014268398284912, "train/mean_reward/goal_5": -1.5075465362322957, "train/final_reward/goal_5": -1.3129469156265259, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -3.022298812866211, "train/max_reward/goal_6": -1.4873508214950562, "train/mean_reward/goal_6": -2.177656871707816, "train/final_reward/goal_6": -1.8694629669189453, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.065303087234497, "train/max_reward/goal_7": -1.9943701028823853, "train/mean_reward/goal_7": -2.579596586917576, "train/final_reward/goal_7": -2.471700429916382, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.045834541320801, "train/max_reward/goal_8": -1.5906636714935303, "train/mean_reward/goal_8": -2.372223330171485, "train/final_reward/goal_8": -2.663722276687622, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.823970079421997, "train/max_reward/goal_9": -1.419463038444519, "train/mean_reward/goal_9": -1.8145976615579504, "train/final_reward/goal_9": -1.419463038444519, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.2458343505859375, "train/max_reward/goal_10": -0.9800328612327576, "train/mean_reward/goal_10": -1.6353996701930698, "train/final_reward/goal_10": -1.863722324371338, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.6992759704589844, "train/max_reward/goal_11": -1.0773710012435913, "train/mean_reward/goal_11": -2.2322189729464683, "train/final_reward/goal_11": -2.471700429916382}
{"step": 0, "dataset_size": 300.0, "train/return": -167.5802025794983, "train/length": 75.0, "train/episodes": 4.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.685115337371826, "train/max_reward/goal_0": -1.5590752363204956, "train/mean_reward/goal_0": -2.2326334244326542, "train/final_reward/goal_0": -2.0039079189300537, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.140970230102539, "train/max_reward/goal_1": -1.774152398109436, "train/mean_reward/goal_1": -2.82721419710862, "train/final_reward/goal_1": -3.1369755268096924, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.685115337371826, "train/max_reward/goal_2": -1.5541425943374634, "train/mean_reward/goal_2": -2.2445029130107477, "train/final_reward/goal_2": -2.0039079189300537, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.1487975120544434, "train/max_reward/goal_3": -1.0330710411071777, "train/mean_reward/goal_3": -1.5513757451584465, "train/final_reward/goal_3": -1.566975474357605, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.048797369003296, "train/max_reward/goal_4": -1.2174080610275269, "train/mean_reward/goal_4": -2.2942563436533274, "train/final_reward/goal_4": -2.466975450515747, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.488797426223755, "train/max_reward/goal_5": -0.8941426277160645, "train/mean_reward/goal_5": -1.732248757230608, "train/final_reward/goal_5": -1.906975507736206, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 1.0, "train/mean_success/goal_6": 0.013157894736842105, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.7250726222991943, "train/max_reward/goal_6": -0.653010904788971, "train/mean_reward/goal_6": -1.3197125361153954, "train/final_reward/goal_6": -1.1169754266738892, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.685115337371826, "train/max_reward/goal_7": -1.5541425943374634, "train/mean_reward/goal_7": -2.2464765969075655, "train/final_reward/goal_7": -2.0039079189300537, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.039473684210526314, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.161559581756592, "train/max_reward/goal_8": -0.27789363265037537, "train/mean_reward/goal_8": -1.6326524195702452, "train/final_reward/goal_8": -1.2284703254699707, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.1487975120544434, "train/max_reward/goal_9": -0.7535454034805298, "train/mean_reward/goal_9": -1.5001395870196192, "train/final_reward/goal_9": -1.566975474357605, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.7958476543426514, "train/max_reward/goal_10": -1.2184648513793945, "train/mean_reward/goal_10": -1.7581968448664014, "train/final_reward/goal_10": -1.433024525642395, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.140970230102539, "train/max_reward/goal_11": -1.774152398109436, "train/mean_reward/goal_11": -2.82721419710862, "train/final_reward/goal_11": -3.1369755268096924}
{"step": 0, "dataset_size": 375.0, "train/return": -120.29495656490326, "train/length": 75.0, "train/episodes": 5.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.7285349369049072, "train/max_reward/goal_0": -1.5513876676559448, "train/mean_reward/goal_0": -2.278337034739946, "train/final_reward/goal_0": -1.9483743906021118, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1383090019226074, "train/max_reward/goal_1": -2.100510835647583, "train/mean_reward/goal_1": -2.873688700952028, "train/final_reward/goal_1": -2.9033401012420654, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.7285349369049072, "train/max_reward/goal_2": -1.6289620399475098, "train/mean_reward/goal_2": -2.2907749885006954, "train/final_reward/goal_2": -1.9483743906021118, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.4100492000579834, "train/max_reward/goal_3": -1.1108840703964233, "train/mean_reward/goal_3": -1.6609155629810535, "train/final_reward/goal_3": -1.8098453283309937, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.0736935138702393, "train/max_reward/goal_4": -1.465433955192566, "train/mean_reward/goal_4": -2.4369455717111888, "train/final_reward/goal_4": -2.7098453044891357, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.750049114227295, "train/max_reward/goal_5": -0.9054340124130249, "train/mean_reward/goal_5": -1.8801244803165134, "train/final_reward/goal_5": -2.1498453617095947, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.960049033164978, "train/max_reward/goal_6": -0.8592580556869507, "train/mean_reward/goal_6": -1.348590303408472, "train/final_reward/goal_6": -1.3598452806472778, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.7285349369049072, "train/max_reward/goal_7": -1.6289620399475098, "train/mean_reward/goal_7": -2.29302095739465, "train/final_reward/goal_7": -1.969068169593811, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.05263157894736842, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.1615312099456787, "train/max_reward/goal_8": -0.5076872110366821, "train/mean_reward/goal_8": -1.5637522402562594, "train/final_reward/goal_8": -0.8706537485122681, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.4100492000579834, "train/max_reward/goal_9": -0.7733538150787354, "train/mean_reward/goal_9": -1.6047871834353398, "train/final_reward/goal_9": -1.8098453283309937, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.564272403717041, "train/max_reward/goal_10": -1.157433271408081, "train/mean_reward/goal_10": -1.6469137088248604, "train/final_reward/goal_10": -1.2690682411193848, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1383090019226074, "train/max_reward/goal_11": -2.100510835647583, "train/mean_reward/goal_11": -2.873688700952028, "train/final_reward/goal_11": -2.9033401012420654}
{"step": 0, "dataset_size": 450.0, "train/return": -109.59978038072586, "train/length": 75.0, "train/episodes": 6.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.678250551223755, "train/max_reward/goal_0": -0.7907260656356812, "train/mean_reward/goal_0": -2.250824467131966, "train/final_reward/goal_0": -2.013554334640503, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.13389253616333, "train/max_reward/goal_1": -1.9801533222198486, "train/mean_reward/goal_1": -2.8173290428362394, "train/final_reward/goal_1": -2.898273229598999, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.678250551223755, "train/max_reward/goal_2": -1.373263955116272, "train/mean_reward/goal_2": -2.284471309498737, "train/final_reward/goal_2": -2.013554334640503, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.733031988143921, "train/max_reward/goal_3": -1.0854119062423706, "train/mean_reward/goal_3": -1.814684692182039, "train/final_reward/goal_3": -1.3282731771469116, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.123771905899048, "train/max_reward/goal_4": -1.9044808149337769, "train/mean_reward/goal_4": -2.618856158695723, "train/final_reward/goal_4": -2.2282731533050537, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -3.0730319023132324, "train/max_reward/goal_5": -1.3444808721542358, "train/mean_reward/goal_5": -2.1299099247706565, "train/final_reward/goal_5": -1.6682732105255127, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.283031940460205, "train/max_reward/goal_6": -0.8986416459083557, "train/mean_reward/goal_6": -1.468723059484833, "train/final_reward/goal_6": -1.182189702987671, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.678250551223755, "train/max_reward/goal_7": -1.373263955116272, "train/mean_reward/goal_7": -2.289724440951096, "train/final_reward/goal_7": -2.013554334640503, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.02631578947368421, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.1724467277526855, "train/max_reward/goal_8": -0.6293171644210815, "train/mean_reward/goal_8": -1.4488047071193393, "train/final_reward/goal_8": -1.7021898031234741, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.733031988143921, "train/max_reward/goal_9": -1.183571219444275, "train/mean_reward/goal_9": -1.8175341094795026, "train/final_reward/goal_9": -1.3282731771469116, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.110229253768921, "train/max_reward/goal_10": -0.9521280527114868, "train/mean_reward/goal_10": -1.5091091935571872, "train/final_reward/goal_10": -1.6717268228530884, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.13389253616333, "train/max_reward/goal_11": -1.9801533222198486, "train/mean_reward/goal_11": -2.8173290428362394, "train/final_reward/goal_11": -2.898273229598999}
{"step": 0, "dataset_size": 525.0, "train/return": -121.39314937591553, "train/length": 75.0, "train/episodes": 7.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 1.0, "train/mean_success/goal_0": 0.02631578947368421, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.7183279991149902, "train/max_reward/goal_0": -0.4293655753135681, "train/mean_reward/goal_0": -2.2811340799457147, "train/final_reward/goal_0": -2.6724443435668945, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1413094997406006, "train/max_reward/goal_1": -1.9828537702560425, "train/mean_reward/goal_1": -2.835132358889831, "train/final_reward/goal_1": -2.8772170543670654, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.7183279991149902, "train/max_reward/goal_2": -1.4425989389419556, "train/mean_reward/goal_2": -2.344357131343139, "train/final_reward/goal_2": -2.6724443435668945, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.2163236141204834, "train/max_reward/goal_3": -0.9115249514579773, "train/mean_reward/goal_3": -1.5331453249642724, "train/final_reward/goal_3": -1.8359681367874146, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.116323709487915, "train/max_reward/goal_4": -0.9128537178039551, "train/mean_reward/goal_4": -2.376589637837912, "train/final_reward/goal_4": -2.7359681129455566, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 1.0, "train/mean_success/goal_5": 0.02631578947368421, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.556323528289795, "train/max_reward/goal_5": -0.6428537368774414, "train/mean_reward/goal_5": -1.82356154134399, "train/final_reward/goal_5": -2.1759681701660156, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.8282244205474854, "train/max_reward/goal_6": -0.8159942030906677, "train/mean_reward/goal_6": -1.415137084691148, "train/final_reward/goal_6": -1.3859682083129883, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.7183279991149902, "train/max_reward/goal_7": -1.4425989389419556, "train/mean_reward/goal_7": -2.3467255532741547, "train/final_reward/goal_7": -2.6724443435668945, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.02631578947368421, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.4915504455566406, "train/max_reward/goal_8": -0.3461524248123169, "train/mean_reward/goal_8": -1.6578650678458966, "train/final_reward/goal_8": -1.172444462776184, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.2163236141204834, "train/max_reward/goal_9": -0.7769185900688171, "train/mean_reward/goal_9": -1.6075008942892677, "train/final_reward/goal_9": -1.8359681367874146, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.130147933959961, "train/max_reward/goal_10": -1.0798025131225586, "train/mean_reward/goal_10": -1.7810064836552268, "train/final_reward/goal_10": -1.672444462776184, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1413094997406006, "train/max_reward/goal_11": -1.9828537702560425, "train/mean_reward/goal_11": -2.835132358889831, "train/final_reward/goal_11": -2.8772170543670654}
{"step": 0, "dataset_size": 600.0, "train/return": -162.25720119476318, "train/length": 75.0, "train/episodes": 8.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.140944480895996, "train/max_reward/goal_0": -2.27717661857605, "train/mean_reward/goal_0": -2.8010177047629106, "train/final_reward/goal_0": -2.3808951377868652, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.6612157821655273, "train/max_reward/goal_1": -1.3520925045013428, "train/mean_reward/goal_1": -2.1681991595970955, "train/final_reward/goal_1": -1.4009701013565063, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.140944480895996, "train/max_reward/goal_2": -2.27717661857605, "train/mean_reward/goal_2": -2.8010177047629106, "train/final_reward/goal_2": -2.3808951377868652, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.3972129821777344, "train/max_reward/goal_3": -1.0727808475494385, "train/mean_reward/goal_3": -1.7683571765297337, "train/final_reward/goal_3": -1.906734585762024, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 1.0, "train/mean_success/goal_4": 0.013157894736842105, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.5002152919769287, "train/max_reward/goal_4": -0.6397739052772522, "train/mean_reward/goal_4": -1.6289001993442838, "train/final_reward/goal_4": -2.2067346572875977, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.0572128295898438, "train/max_reward/goal_5": -0.9712657928466797, "train/mean_reward/goal_5": -1.4724445876322294, "train/final_reward/goal_5": -1.4367345571517944, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.847212791442871, "train/max_reward/goal_6": -1.1571767330169678, "train/mean_reward/goal_6": -2.0584812211362937, "train/final_reward/goal_6": -1.2608951330184937, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.1303446292877197, "train/max_reward/goal_7": -1.9480448961257935, "train/mean_reward/goal_7": -2.5445089418637123, "train/final_reward/goal_7": -1.95692777633667, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.1310501098632812, "train/max_reward/goal_8": -1.9835419654846191, "train/mean_reward/goal_8": -2.488248108248962, "train/final_reward/goal_8": -3.010895252227783, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.3972129821777344, "train/max_reward/goal_9": -1.2997143268585205, "train/mean_reward/goal_9": -1.7803073760710264, "train/final_reward/goal_9": -1.8367345333099365, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.5760085582733154, "train/max_reward/goal_10": -0.9528405666351318, "train/mean_reward/goal_10": -1.7153258449152897, "train/final_reward/goal_10": -2.4722900390625, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.6612157821655273, "train/max_reward/goal_11": -1.3263976573944092, "train/mean_reward/goal_11": -2.1455838084220886, "train/final_reward/goal_11": -1.906734585762024}
{"step": 0, "dataset_size": 675.0, "train/return": -121.157928109169, "train/length": 75.0, "train/episodes": 9.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.135758399963379, "train/max_reward/goal_0": -2.4504401683807373, "train/mean_reward/goal_0": -2.815937487702621, "train/final_reward/goal_0": -2.8984642028808594, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.07894736842105263, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.69320011138916, "train/max_reward/goal_1": -0.394893079996109, "train/mean_reward/goal_1": -1.681765675152603, "train/final_reward/goal_1": -1.1639442443847656, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.135758399963379, "train/max_reward/goal_2": -2.4504401683807373, "train/mean_reward/goal_2": -2.815937487702621, "train/final_reward/goal_2": -2.8984642028808594, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.267503499984741, "train/max_reward/goal_3": -1.359340786933899, "train/mean_reward/goal_3": -1.8548282337816138, "train/final_reward/goal_3": -1.813544750213623, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.5210134983062744, "train/max_reward/goal_4": -0.8858314156532288, "train/mean_reward/goal_4": -1.6141338034680015, "train/final_reward/goal_4": -2.1135447025299072, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -1.9275035858154297, "train/max_reward/goal_5": -0.9683413505554199, "train/mean_reward/goal_5": -1.4965312920118634, "train/final_reward/goal_5": -1.3673218488693237, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.717503547668457, "train/max_reward/goal_6": -1.3554285764694214, "train/mean_reward/goal_6": -2.2112982539754165, "train/final_reward/goal_6": -1.7784641981124878, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.0675036907196045, "train/max_reward/goal_7": -1.9064230918884277, "train/mean_reward/goal_7": -2.57035978216874, "train/final_reward/goal_7": -2.1284642219543457, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.105428695678711, "train/max_reward/goal_8": -1.8609497547149658, "train/mean_reward/goal_8": -2.338860422372818, "train/final_reward/goal_8": -2.754721164703369, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.267503499984741, "train/max_reward/goal_9": -1.254417896270752, "train/mean_reward/goal_9": -1.8286826061575037, "train/final_reward/goal_9": -1.7435448169708252, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.3777568340301514, "train/max_reward/goal_10": -1.0445899963378906, "train/mean_reward/goal_10": -1.5993385346312272, "train/final_reward/goal_10": -1.9547210931777954, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.69320011138916, "train/max_reward/goal_11": -0.9681519865989685, "train/mean_reward/goal_11": -1.7796217650175095, "train/final_reward/goal_11": -1.813544750213623}
{"step": 0, "dataset_size": 750.0, "train/return": -118.38233041763306, "train/length": 75.0, "train/episodes": 10.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.7056491374969482, "train/max_reward/goal_0": -0.9599713683128357, "train/mean_reward/goal_0": -2.2128653283181943, "train/final_reward/goal_0": -1.8381129503250122, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1384341716766357, "train/max_reward/goal_1": -1.6223785877227783, "train/mean_reward/goal_1": -2.64776191429088, "train/final_reward/goal_1": -2.901031017303467, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 1.0, "train/mean_success/goal_2": 0.039473684210526314, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.7056491374969482, "train/max_reward/goal_2": -0.648456871509552, "train/mean_reward/goal_2": -2.1705534709127328, "train/final_reward/goal_2": -1.8381129503250122, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.237196207046509, "train/max_reward/goal_3": -0.7466633915901184, "train/mean_reward/goal_3": -1.5689594275073002, "train/final_reward/goal_3": -1.8121541738510132, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.1371960639953613, "train/max_reward/goal_4": -0.7114139199256897, "train/mean_reward/goal_4": -2.3181157629740867, "train/final_reward/goal_4": -2.7121541500091553, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 1.0, "train/mean_success/goal_5": 0.05263157894736842, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.5771961212158203, "train/max_reward/goal_5": -0.6285861134529114, "train/mean_reward/goal_5": -1.7256784243019003, "train/final_reward/goal_5": -2.1521542072296143, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.8607531785964966, "train/max_reward/goal_6": -0.8182778358459473, "train/mean_reward/goal_6": -1.40458703197931, "train/final_reward/goal_6": -1.362154245376587, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 1.0, "train/mean_success/goal_7": 0.05263157894736842, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.7056491374969482, "train/max_reward/goal_7": -0.2827795445919037, "train/mean_reward/goal_7": -2.1170141230288304, "train/final_reward/goal_7": -1.8381129503250122, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.02631578947368421, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.0803771018981934, "train/max_reward/goal_8": -0.29036808013916016, "train/mean_reward/goal_8": -1.8065329158776684, "train/final_reward/goal_8": -0.7752713561058044, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.237196207046509, "train/max_reward/goal_9": -0.775734007358551, "train/mean_reward/goal_9": -1.5860030392282887, "train/final_reward/goal_9": -1.8121541738510132, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.1180505752563477, "train/max_reward/goal_10": -1.1454145908355713, "train/mean_reward/goal_10": -1.9919165561073704, "train/final_reward/goal_10": -1.1878458261489868, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1384341716766357, "train/max_reward/goal_11": -1.215721607208252, "train/mean_reward/goal_11": -2.631092849530672, "train/final_reward/goal_11": -2.901031017303467}
{"step": 0, "dataset_size": 825.0, "train/return": -118.49939280748367, "train/length": 75.0, "train/episodes": 11.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.1404335498809814, "train/max_reward/goal_0": -1.8834701776504517, "train/mean_reward/goal_0": -2.735694806826742, "train/final_reward/goal_0": -2.5733726024627686, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.07894736842105263, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.6818137168884277, "train/max_reward/goal_1": -0.15424437820911407, "train/mean_reward/goal_1": -1.8762631035949056, "train/final_reward/goal_1": -2.3961551189422607, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.1404335498809814, "train/max_reward/goal_2": -1.946665644645691, "train/mean_reward/goal_2": -2.736526326129311, "train/final_reward/goal_2": -2.5733726024627686, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.4477059841156006, "train/max_reward/goal_3": -0.8058418035507202, "train/mean_reward/goal_3": -1.8287861496210098, "train/final_reward/goal_3": -2.139812707901001, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.3682892322540283, "train/max_reward/goal_4": -0.770219624042511, "train/mean_reward/goal_4": -1.5768559394698394, "train/final_reward/goal_4": -1.4316424131393433, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.107706069946289, "train/max_reward/goal_5": -0.8004580736160278, "train/mean_reward/goal_5": -1.4978000380490955, "train/final_reward/goal_5": -1.7998125553131104, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.8977060317993164, "train/max_reward/goal_6": -0.8530306816101074, "train/mean_reward/goal_6": -2.0999497018362345, "train/final_reward/goal_6": -2.5898125171661377, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.141489028930664, "train/max_reward/goal_7": -1.8115957975387573, "train/mean_reward/goal_7": -2.5854416160207045, "train/final_reward/goal_7": -2.939812660217285, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.1385650634765625, "train/max_reward/goal_8": -1.8135868310928345, "train/mean_reward/goal_8": -2.401932757151754, "train/final_reward/goal_8": -1.9433727264404297, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.4477059841156006, "train/max_reward/goal_9": -1.140458106994629, "train/mean_reward/goal_9": -1.821208423689792, "train/final_reward/goal_9": -2.139812707901001, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.9781103134155273, "train/max_reward/goal_10": -0.8666141629219055, "train/mean_reward/goal_10": -1.682647048642761, "train/final_reward/goal_10": -1.3961552381515503, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.6818137168884277, "train/max_reward/goal_11": -0.8454655408859253, "train/mean_reward/goal_11": -1.9626636426699788, "train/final_reward/goal_11": -2.3961551189422607}
{"step": 0, "dataset_size": 900.0, "train/return": -177.12331783771515, "train/length": 75.0, "train/episodes": 12.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.1378684043884277, "train/max_reward/goal_0": -1.5711416006088257, "train/mean_reward/goal_0": -2.6950079955552755, "train/final_reward/goal_0": -2.799769878387451, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.02631578947368421, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.7183499336242676, "train/max_reward/goal_1": -0.3576211929321289, "train/mean_reward/goal_1": -1.9581577652379085, "train/final_reward/goal_1": -1.8595471382141113, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.1378684043884277, "train/max_reward/goal_2": -1.664626955986023, "train/mean_reward/goal_2": -2.6968973639764284, "train/final_reward/goal_2": -2.799769878387451, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -3.128448247909546, "train/max_reward/goal_3": -1.2101739645004272, "train/mean_reward/goal_3": -2.1270550944303213, "train/final_reward/goal_3": -1.9605154991149902, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.6303341388702393, "train/max_reward/goal_4": -1.0438605546951294, "train/mean_reward/goal_4": -1.7391805680174577, "train/final_reward/goal_4": -2.2605154514312744, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -3.1401212215423584, "train/max_reward/goal_5": -0.8775256276130676, "train/mean_reward/goal_5": -1.8146825142596896, "train/final_reward/goal_5": -1.4905154705047607, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -3.064753532409668, "train/max_reward/goal_6": -1.2691020965576172, "train/mean_reward/goal_6": -2.363269236526991, "train/final_reward/goal_6": -1.6797699928283691, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.1239466667175293, "train/max_reward/goal_7": -2.1151490211486816, "train/mean_reward/goal_7": -2.6455893045977543, "train/final_reward/goal_7": -2.13091778755188, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.019102096557617, "train/max_reward/goal_8": -1.7474291324615479, "train/mean_reward/goal_8": -2.223168189588346, "train/final_reward/goal_8": -2.8534152507781982, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -3.128448247909546, "train/max_reward/goal_9": -1.1801375150680542, "train/mean_reward/goal_9": -2.118723789328023, "train/final_reward/goal_9": -1.8905155658721924, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.464083194732666, "train/max_reward/goal_10": -1.0, "train/mean_reward/goal_10": -1.5404451960011531, "train/final_reward/goal_10": -2.053415298461914, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.7183499336242676, "train/max_reward/goal_11": -0.7457696199417114, "train/mean_reward/goal_11": -1.9822966660323895, "train/final_reward/goal_11": -1.9605154991149902}
{"step": 0, "dataset_size": 975.0, "train/return": -177.6932371854782, "train/length": 75.0, "train/episodes": 13.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.682502269744873, "train/max_reward/goal_0": -1.5087147951126099, "train/mean_reward/goal_0": -2.4814524132954445, "train/final_reward/goal_0": -2.102400779724121, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.139110803604126, "train/max_reward/goal_1": -2.0799717903137207, "train/mean_reward/goal_1": -2.759337569537916, "train/final_reward/goal_1": -2.946230888366699, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.682502269744873, "train/max_reward/goal_2": -1.9262560606002808, "train/mean_reward/goal_2": -2.491942446482809, "train/final_reward/goal_2": -2.102400779724121, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.0608279705047607, "train/max_reward/goal_3": -0.8585846424102783, "train/mean_reward/goal_3": -1.4064260266329114, "train/final_reward/goal_3": -1.7669545412063599, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.9608280658721924, "train/max_reward/goal_4": -1.6500358581542969, "train/mean_reward/goal_4": -2.3597799084688487, "train/final_reward/goal_4": -2.666954517364502, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.4008281230926514, "train/max_reward/goal_5": -1.0962560176849365, "train/mean_reward/goal_5": -1.735604918316791, "train/final_reward/goal_5": -2.106954574584961, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.8522562980651855, "train/max_reward/goal_6": -0.7087147831916809, "train/mean_reward/goal_6": -1.463584857551675, "train/final_reward/goal_6": -1.316954493522644, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.682502269744873, "train/max_reward/goal_7": -1.9562560319900513, "train/mean_reward/goal_7": -2.493126657448317, "train/final_reward/goal_7": -2.102400779724121, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.205857038497925, "train/max_reward/goal_8": -0.9784889221191406, "train/mean_reward/goal_8": -1.7620783432533866, "train/final_reward/goal_8": -0.9784889221191406, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.0608279705047607, "train/max_reward/goal_9": -1.1306716203689575, "train/mean_reward/goal_9": -1.7019137536224567, "train/final_reward/goal_9": -1.7669545412063599, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.005856990814209, "train/max_reward/goal_10": -1.2330454587936401, "train/mean_reward/goal_10": -2.0083916391197003, "train/final_reward/goal_10": -1.2330454587936401, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.139110803604126, "train/max_reward/goal_11": -2.0799717903137207, "train/mean_reward/goal_11": -2.759337569537916, "train/final_reward/goal_11": -2.946230888366699}
{"step": 0, "dataset_size": 1050.0, "train/return": -121.86561053991318, "train/length": 75.0, "train/episodes": 14.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.1405599117279053, "train/max_reward/goal_0": -1.5810054540634155, "train/mean_reward/goal_0": -2.6568447335770258, "train/final_reward/goal_0": -2.765409231185913, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.02631578947368421, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.708874225616455, "train/max_reward/goal_1": -0.5405028462409973, "train/mean_reward/goal_1": -2.049370560991137, "train/final_reward/goal_1": -1.6272047758102417, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.1405599117279053, "train/max_reward/goal_2": -1.765690565109253, "train/mean_reward/goal_2": -2.6619841832863655, "train/final_reward/goal_2": -2.765409231185913, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 1.0, "train/mean_success/goal_3": 0.013157894736842105, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.2869248390197754, "train/max_reward/goal_3": -0.6975193619728088, "train/mean_reward/goal_3": -1.6174582642944235, "train/final_reward/goal_3": -1.947776198387146, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.5217840671539307, "train/max_reward/goal_4": -1.0477761030197144, "train/mean_reward/goal_4": -1.7327654408781152, "train/final_reward/goal_4": -1.0477761030197144, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 1.0, "train/mean_success/goal_5": 0.013157894736842105, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -1.9469248056411743, "train/max_reward/goal_5": -0.5912175178527832, "train/mean_reward/goal_5": -1.4447969049215317, "train/final_reward/goal_5": -1.607776165008545, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 1.0, "train/mean_success/goal_6": 0.02631578947368421, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.736924886703491, "train/max_reward/goal_6": -0.6216036081314087, "train/mean_reward/goal_6": -1.8611385532115634, "train/final_reward/goal_6": -2.3977761268615723, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.0869247913360596, "train/max_reward/goal_7": -1.583888292312622, "train/mean_reward/goal_7": -2.489506570916427, "train/final_reward/goal_7": -2.7477762699127197, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.1349196434020996, "train/max_reward/goal_8": -1.8958009481430054, "train/mean_reward/goal_8": -2.612917440502267, "train/final_reward/goal_8": -2.135409116744995, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.2869248390197754, "train/max_reward/goal_9": -0.9912175536155701, "train/mean_reward/goal_9": -1.7188336794313632, "train/final_reward/goal_9": -1.947776198387146, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.0874946117401123, "train/max_reward/goal_10": -1.064640760421753, "train/mean_reward/goal_10": -1.9521901105579578, "train/final_reward/goal_10": -1.335409164428711, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.708874225616455, "train/max_reward/goal_11": -1.0847790241241455, "train/mean_reward/goal_11": -2.12858541545115, "train/final_reward/goal_11": -1.6272047758102417}
{"step": 0, "dataset_size": 1125.0, "train/return": -116.40748035907745, "train/length": 75.0, "train/episodes": 15.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 1.0, "train/mean_success/goal_0": 0.039473684210526314, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.6747725009918213, "train/max_reward/goal_0": -0.47747039794921875, "train/mean_reward/goal_0": -2.064840441471652, "train/final_reward/goal_0": -2.281669855117798, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1398167610168457, "train/max_reward/goal_1": -2.146463632583618, "train/mean_reward/goal_1": -2.910225554516441, "train/final_reward/goal_1": -2.7823710441589355, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.6747725009918213, "train/max_reward/goal_2": -0.9631975889205933, "train/mean_reward/goal_2": -2.133533651891508, "train/final_reward/goal_2": -2.281669855117798, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.512732982635498, "train/max_reward/goal_3": -1.1677442789077759, "train/mean_reward/goal_3": -1.6881122400886135, "train/final_reward/goal_3": -1.930814266204834, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.1067380905151367, "train/max_reward/goal_4": -1.6494327783584595, "train/mean_reward/goal_4": -2.5072996381082033, "train/final_reward/goal_4": -2.8308141231536865, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.8527328968048096, "train/max_reward/goal_5": -1.089432716369629, "train/mean_reward/goal_5": -1.9635271210419505, "train/final_reward/goal_5": -2.2708141803741455, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.0627329349517822, "train/max_reward/goal_6": -0.7177442312240601, "train/mean_reward/goal_6": -1.351552534260248, "train/final_reward/goal_6": -1.4808142185211182, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.6747725009918213, "train/max_reward/goal_7": -0.9931976199150085, "train/mean_reward/goal_7": -2.138270493400724, "train/final_reward/goal_7": -2.281669855117798, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.06578947368421052, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.300147771835327, "train/max_reward/goal_8": -0.3131153881549835, "train/mean_reward/goal_8": -1.5480176994675083, "train/final_reward/goal_8": -1.3585222959518433, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.512732982635498, "train/max_reward/goal_9": -0.9873903393745422, "train/mean_reward/goal_9": -1.6442282490040128, "train/final_reward/goal_9": -1.930814266204834, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.4235363006591797, "train/max_reward/goal_10": -1.07254159450531, "train/mean_reward/goal_10": -1.5585626881373555, "train/final_reward/goal_10": -1.6585222482681274, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1398167610168457, "train/max_reward/goal_11": -2.146463632583618, "train/mean_reward/goal_11": -2.910225554516441, "train/final_reward/goal_11": -2.7823710441589355}
{"step": 0, "dataset_size": 1200.0, "train/return": -165.28371226787567, "train/length": 75.0, "train/episodes": 16.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.7171835899353027, "train/max_reward/goal_0": -1.0467597246170044, "train/mean_reward/goal_0": -2.194546740306051, "train/final_reward/goal_0": -1.7903499603271484, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1403844356536865, "train/max_reward/goal_1": -2.115520715713501, "train/mean_reward/goal_1": -2.8726133923781547, "train/final_reward/goal_1": -3.1079843044281006, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.7171835899353027, "train/max_reward/goal_2": -1.2606143951416016, "train/mean_reward/goal_2": -2.207818230516032, "train/final_reward/goal_2": -1.7903499603271484, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.31827974319458, "train/max_reward/goal_3": -1.1070672273635864, "train/mean_reward/goal_3": -1.605019080011468, "train/final_reward/goal_3": -1.605201005935669, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.136322021484375, "train/max_reward/goal_4": -1.4106637239456177, "train/mean_reward/goal_4": -2.3611283725813816, "train/final_reward/goal_4": -2.5052011013031006, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.6582796573638916, "train/max_reward/goal_5": -0.8855206370353699, "train/mean_reward/goal_5": -1.8155948762830936, "train/final_reward/goal_5": -1.94520103931427, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.8682798147201538, "train/max_reward/goal_6": -0.7881056666374207, "train/mean_reward/goal_6": -1.3368042017284192, "train/final_reward/goal_6": -1.1552010774612427, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.7171835899353027, "train/max_reward/goal_7": -1.2606143951416016, "train/mean_reward/goal_7": -2.2101866508785046, "train/final_reward/goal_7": -1.7903499603271484, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.039473684210526314, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.206378698348999, "train/max_reward/goal_8": -0.5840436816215515, "train/mean_reward/goal_8": -1.6008130092369883, "train/final_reward/goal_8": -1.2901928424835205, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.31827974319458, "train/max_reward/goal_9": -0.8843967914581299, "train/mean_reward/goal_9": -1.5306653662731773, "train/final_reward/goal_9": -1.605201005935669, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.6050033569335938, "train/max_reward/goal_10": -1.0768587589263916, "train/mean_reward/goal_10": -1.6835395693778992, "train/final_reward/goal_10": -1.394798994064331, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1403844356536865, "train/max_reward/goal_11": -2.115520715713501, "train/mean_reward/goal_11": -2.8726133923781547, "train/final_reward/goal_11": -3.1079843044281006}
{"step": 0, "dataset_size": 1275.0, "train/return": -99.91752898693085, "train/length": 75.0, "train/episodes": 17.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.6887319087982178, "train/max_reward/goal_0": -0.8358448147773743, "train/mean_reward/goal_0": -2.035134840168451, "train/final_reward/goal_0": -2.6123483180999756, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1413934230804443, "train/max_reward/goal_1": -2.307340383529663, "train/mean_reward/goal_1": -2.973683454488453, "train/final_reward/goal_1": -3.1073179244995117, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 1.0, "train/mean_success/goal_2": 0.013157894736842105, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.6887319087982178, "train/max_reward/goal_2": -0.6700828671455383, "train/mean_reward/goal_2": -1.982727648396241, "train/final_reward/goal_2": -2.6123483180999756, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.4058449268341064, "train/max_reward/goal_3": -1.250160574913025, "train/mean_reward/goal_3": -1.6707458731375242, "train/final_reward/goal_3": -1.6398060321807861, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.1128885746002197, "train/max_reward/goal_4": -2.1288087368011475, "train/mean_reward/goal_4": -2.5475584519536874, "train/final_reward/goal_4": -2.5058672428131104, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.745844841003418, "train/max_reward/goal_5": -1.5688087940216064, "train/mean_reward/goal_5": -1.9913475529143685, "train/final_reward/goal_5": -1.9458673000335693, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.9558448791503906, "train/max_reward/goal_6": -0.9321404099464417, "train/mean_reward/goal_6": -1.3357849858309094, "train/final_reward/goal_6": -1.2470266819000244, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.6887319087982178, "train/max_reward/goal_7": -0.7666770219802856, "train/mean_reward/goal_7": -1.9795196699468713, "train/final_reward/goal_7": -2.6123483180999756, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.02631578947368421, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.1528239250183105, "train/max_reward/goal_8": -0.4165182411670685, "train/mean_reward/goal_8": -1.7013324942243726, "train/final_reward/goal_8": -1.767026662826538, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.4058449268341064, "train/max_reward/goal_9": -1.2288087606430054, "train/mean_reward/goal_9": -1.6635142611829858, "train/final_reward/goal_9": -1.6058672666549683, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -1.8920271396636963, "train/max_reward/goal_10": -0.7619084119796753, "train/mean_reward/goal_10": -1.4396452166532214, "train/final_reward/goal_10": -1.6123483180999756, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1413934230804443, "train/max_reward/goal_11": -2.307340383529663, "train/mean_reward/goal_11": -2.973683454488453, "train/final_reward/goal_11": -3.1073179244995117}
{"step": 0, "dataset_size": 1350.0, "train/return": -214.5868239402771, "train/length": 75.0, "train/episodes": 18.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.122990369796753, "train/max_reward/goal_0": -2.3646397590637207, "train/mean_reward/goal_0": -2.862608733930086, "train/final_reward/goal_0": -3.075406074523926, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.013157894736842105, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.706604480743408, "train/max_reward/goal_1": -0.5059834122657776, "train/mean_reward/goal_1": -2.199663574758329, "train/final_reward/goal_1": -1.0208426713943481, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.122990369796753, "train/max_reward/goal_2": -2.3646397590637207, "train/mean_reward/goal_2": -2.862608733930086, "train/final_reward/goal_2": -3.075406074523926, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.8499062061309814, "train/max_reward/goal_3": -0.9733706712722778, "train/mean_reward/goal_3": -1.8616259945066351, "train/final_reward/goal_3": -1.6377793550491333, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 1.0, "train/mean_success/goal_4": 0.013157894736842105, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.3570234775543213, "train/max_reward/goal_4": -0.6775180697441101, "train/mean_reward/goal_4": -1.7848324516886158, "train/final_reward/goal_4": -1.5810662508010864, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.509906053543091, "train/max_reward/goal_5": -0.8025322556495667, "train/mean_reward/goal_5": -1.5160208603269176, "train/final_reward/goal_5": -1.2977793216705322, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -3.137855052947998, "train/max_reward/goal_6": -1.2446397542953491, "train/mean_reward/goal_6": -2.1824450822252977, "train/final_reward/goal_6": -2.0877792835235596, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.124279260635376, "train/max_reward/goal_7": -1.6732476949691772, "train/mean_reward/goal_7": -2.556166245749122, "train/final_reward/goal_7": -2.437779188156128, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.1098146438598633, "train/max_reward/goal_8": -1.9215502738952637, "train/mean_reward/goal_8": -2.404850357457211, "train/final_reward/goal_8": -2.445405960083008, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.8499062061309814, "train/max_reward/goal_9": -0.9733706712722778, "train/mean_reward/goal_9": -1.8398081189707707, "train/final_reward/goal_9": -1.6377793550491333, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.4885456562042236, "train/max_reward/goal_10": -1.239186406135559, "train/mean_reward/goal_10": -1.705190266433515, "train/final_reward/goal_10": -1.6454060077667236, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.706604480743408, "train/max_reward/goal_11": -0.8124707937240601, "train/mean_reward/goal_11": -2.2201300639855233, "train/final_reward/goal_11": -1.2810662984848022}
{"step": 0, "dataset_size": 1425.0, "train/return": -104.41733396053314, "train/length": 75.0, "train/episodes": 19.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.698880434036255, "train/max_reward/goal_0": -1.309740424156189, "train/mean_reward/goal_0": -2.380719997380909, "train/final_reward/goal_0": -2.2328386306762695, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1414124965667725, "train/max_reward/goal_1": -1.6809264421463013, "train/mean_reward/goal_1": -2.769891464396527, "train/final_reward/goal_1": -2.7413408756256104, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.698880434036255, "train/max_reward/goal_2": -1.6809264421463013, "train/mean_reward/goal_2": -2.4023541086598446, "train/final_reward/goal_2": -2.2328386306762695, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 1.0, "train/mean_success/goal_3": 0.09210526315789473, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.211463212966919, "train/max_reward/goal_3": -0.25959983468055725, "train/mean_reward/goal_3": -1.4300272574550228, "train/final_reward/goal_3": -1.9718444347381592, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.1114633083343506, "train/max_reward/goal_4": -1.1062604188919067, "train/mean_reward/goal_4": -2.3350402336371574, "train/final_reward/goal_4": -2.8718442916870117, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.5514631271362305, "train/max_reward/goal_5": -0.9248252511024475, "train/mean_reward/goal_5": -1.771784303219695, "train/final_reward/goal_5": -2.3118443489074707, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 1.0, "train/mean_success/goal_6": 0.039473684210526314, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.8323897123336792, "train/max_reward/goal_6": -0.5007646679878235, "train/mean_reward/goal_6": -1.380501297743697, "train/final_reward/goal_6": -1.5218443870544434, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.698880434036255, "train/max_reward/goal_7": -1.6809264421463013, "train/mean_reward/goal_7": -2.40227451293092, "train/final_reward/goal_7": -2.2328386306762695, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.4612934589385986, "train/max_reward/goal_8": -0.7328386902809143, "train/mean_reward/goal_8": -1.7211029043323116, "train/final_reward/goal_8": -0.7328386902809143, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.211463212966919, "train/max_reward/goal_9": -0.9663214087486267, "train/mean_reward/goal_9": -1.6257006306397288, "train/final_reward/goal_9": -1.9718444347381592, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.096759557723999, "train/max_reward/goal_10": -1.218923807144165, "train/mean_reward/goal_10": -1.9099116921424866, "train/final_reward/goal_10": -1.2563806772232056, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1414124965667725, "train/max_reward/goal_11": -1.6809264421463013, "train/mean_reward/goal_11": -2.7688531765812323, "train/final_reward/goal_11": -2.7413408756256104}
{"step": 0, "dataset_size": 1500.0, "train/return": -173.79193544387817, "train/length": 75.0, "train/episodes": 20.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.139150857925415, "train/max_reward/goal_0": -1.6077011823654175, "train/mean_reward/goal_0": -2.7984078965689005, "train/final_reward/goal_0": -3.1259303092956543, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.013157894736842105, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.755812168121338, "train/max_reward/goal_1": -0.5508909821510315, "train/mean_reward/goal_1": -2.206443602317258, "train/final_reward/goal_1": -1.250400185585022, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.139150857925415, "train/max_reward/goal_2": -1.6077011823654175, "train/mean_reward/goal_2": -2.7984078965689005, "train/final_reward/goal_2": -3.1259303092956543, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -3.1054840087890625, "train/max_reward/goal_3": -1.344588279724121, "train/mean_reward/goal_3": -1.9403460261068846, "train/final_reward/goal_3": -1.8524281978607178, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.5971710681915283, "train/max_reward/goal_4": -0.9374218583106995, "train/mean_reward/goal_4": -1.9232580732358129, "train/final_reward/goal_4": -2.152428150177002, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.9333438873291016, "train/max_reward/goal_5": -1.167203426361084, "train/mean_reward/goal_5": -1.6596138226358514, "train/final_reward/goal_5": -1.3824282884597778, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -3.0373897552490234, "train/max_reward/goal_6": -1.2288966178894043, "train/mean_reward/goal_6": -2.252641649622666, "train/final_reward/goal_6": -2.037254810333252, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.1393015384674072, "train/max_reward/goal_7": -2.0272035598754883, "train/mean_reward/goal_7": -2.626425034121463, "train/final_reward/goal_7": -2.3872549533843994, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.102996587753296, "train/max_reward/goal_8": -1.149739146232605, "train/mean_reward/goal_8": -2.301864139343563, "train/final_reward/goal_8": -2.4959304332733154, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -3.1054840087890625, "train/max_reward/goal_9": -1.4795567989349365, "train/mean_reward/goal_9": -1.960511293850447, "train/final_reward/goal_9": -1.78242826461792, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.504288673400879, "train/max_reward/goal_10": -1.0, "train/mean_reward/goal_10": -1.628426918857976, "train/final_reward/goal_10": -1.6959303617477417, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.755812168121338, "train/max_reward/goal_11": -1.3634461164474487, "train/mean_reward/goal_11": -2.2702667054377104, "train/final_reward/goal_11": -1.8524281978607178}
{"step": 0, "dataset_size": 1575.0, "train/return": -175.22170650959015, "train/length": 75.0, "train/episodes": 21.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.715149402618408, "train/max_reward/goal_0": -1.3414357900619507, "train/mean_reward/goal_0": -2.339921152905414, "train/final_reward/goal_0": -2.4344799518585205, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1415457725524902, "train/max_reward/goal_1": -2.287984609603882, "train/mean_reward/goal_1": -2.845082402229309, "train/final_reward/goal_1": -3.13152813911438, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.715149402618408, "train/max_reward/goal_2": -1.5458974838256836, "train/mean_reward/goal_2": -2.3588655355729555, "train/final_reward/goal_2": -2.4344799518585205, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.2463417053222656, "train/max_reward/goal_3": -0.717984676361084, "train/mean_reward/goal_3": -1.587461204905259, "train/final_reward/goal_3": -1.561528205871582, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.13684344291687, "train/max_reward/goal_4": -1.4300943613052368, "train/mean_reward/goal_4": -2.3770985085713234, "train/final_reward/goal_4": -2.4615283012390137, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.5863418579101562, "train/max_reward/goal_5": -1.0688024759292603, "train/mean_reward/goal_5": -1.832854594054975, "train/final_reward/goal_5": -1.901528239250183, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 1.0, "train/mean_success/goal_6": 0.02631578947368421, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.813923716545105, "train/max_reward/goal_6": -0.3806658983230591, "train/mean_reward/goal_6": -1.3617313245409413, "train/final_reward/goal_6": -1.536573052406311, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.715149402618408, "train/max_reward/goal_7": -1.575897455215454, "train/mean_reward/goal_7": -2.3612339590725147, "train/final_reward/goal_7": -2.4344799518585205, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.05263157894736842, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.1637492179870605, "train/max_reward/goal_8": -0.3550325632095337, "train/mean_reward/goal_8": -1.5945853336076987, "train/final_reward/goal_8": -2.0565731525421143, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.2463417053222656, "train/max_reward/goal_9": -0.9823532700538635, "train/mean_reward/goal_9": -1.614106566498154, "train/final_reward/goal_9": -1.561528205871582, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.963749408721924, "train/max_reward/goal_10": -1.0214805603027344, "train/mean_reward/goal_10": -1.7543311134765023, "train/final_reward/goal_10": -1.438471794128418, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1415457725524902, "train/max_reward/goal_11": -2.287984609603882, "train/mean_reward/goal_11": -2.845082402229309, "train/final_reward/goal_11": -3.13152813911438}
{"step": 0, "dataset_size": 1650.0, "train/return": -169.20231556892395, "train/length": 75.0, "train/episodes": 22.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.135725259780884, "train/max_reward/goal_0": -2.049180269241333, "train/mean_reward/goal_0": -2.766670252147474, "train/final_reward/goal_0": -2.6655619144439697, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.06578947368421052, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.683682441711426, "train/max_reward/goal_1": -0.2522906959056854, "train/mean_reward/goal_1": -2.112236394693977, "train/final_reward/goal_1": -2.317972183227539, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.135725259780884, "train/max_reward/goal_2": -2.049180269241333, "train/mean_reward/goal_2": -2.766670252147474, "train/final_reward/goal_2": -2.6655619144439697, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.9676835536956787, "train/max_reward/goal_3": -1.337047815322876, "train/mean_reward/goal_3": -1.9839902739775808, "train/final_reward/goal_3": -2.0476233959198, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.737142324447632, "train/max_reward/goal_4": -1.0063529014587402, "train/mean_reward/goal_4": -1.784029195183202, "train/final_reward/goal_4": -1.2479721307754517, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -3.1289823055267334, "train/max_reward/goal_5": -1.0871412754058838, "train/mean_reward/goal_5": -1.6626358361620652, "train/final_reward/goal_5": -1.7076234817504883, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -3.1084132194519043, "train/max_reward/goal_6": -1.4057725667953491, "train/mean_reward/goal_6": -2.2876241426718864, "train/final_reward/goal_6": -2.4976234436035156, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.1252055168151855, "train/max_reward/goal_7": -1.8402020931243896, "train/mean_reward/goal_7": -2.619785172374625, "train/final_reward/goal_7": -2.847623348236084, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.127412796020508, "train/max_reward/goal_8": -1.1155017614364624, "train/mean_reward/goal_8": -2.2503400695951363, "train/final_reward/goal_8": -2.0355618000030518, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.9676835536956787, "train/max_reward/goal_9": -1.337047815322876, "train/mean_reward/goal_9": -1.9765281928213019, "train/final_reward/goal_9": -2.0476233959198, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.3274126052856445, "train/max_reward/goal_10": -1.021362066268921, "train/mean_reward/goal_10": -1.5900355153962185, "train/final_reward/goal_10": -1.3179720640182495, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.683682441711426, "train/max_reward/goal_11": -0.9328005909919739, "train/mean_reward/goal_11": -2.179322136860145, "train/final_reward/goal_11": -2.317972183227539}
{"step": 0, "dataset_size": 1725.0, "train/return": -149.36034367978573, "train/length": 75.0, "train/episodes": 23.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 1.0, "train/mean_success/goal_0": 0.05263157894736842, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.709665060043335, "train/max_reward/goal_0": -0.21290795505046844, "train/mean_reward/goal_0": -1.9990386051174842, "train/final_reward/goal_0": -2.625977039337158, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1253821849823, "train/max_reward/goal_1": -2.459944009780884, "train/mean_reward/goal_1": -2.8793630098041736, "train/final_reward/goal_1": -2.6835761070251465, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.709665060043335, "train/max_reward/goal_2": -0.9695888161659241, "train/mean_reward/goal_2": -2.1089698099776317, "train/final_reward/goal_2": -2.625977039337158, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.2532413005828857, "train/max_reward/goal_3": -1.0602850914001465, "train/mean_reward/goal_3": -1.6221311798221187, "train/final_reward/goal_3": -2.029609203338623, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.129944086074829, "train/max_reward/goal_4": -1.798107385635376, "train/mean_reward/goal_4": -2.4426210977529226, "train/final_reward/goal_4": -2.9296090602874756, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.5932412147521973, "train/max_reward/goal_5": -1.2381073236465454, "train/mean_reward/goal_5": -1.879966028426823, "train/final_reward/goal_5": -2.3696091175079346, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.80324125289917, "train/max_reward/goal_6": -0.8537766933441162, "train/mean_reward/goal_6": -1.3341934877006631, "train/final_reward/goal_6": -1.5796091556549072, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.709665060043335, "train/max_reward/goal_7": -0.9995887875556946, "train/mean_reward/goal_7": -2.1164698075307045, "train/final_reward/goal_7": -2.625977039337158, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.02631578947368421, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.192456007003784, "train/max_reward/goal_8": -0.5349409580230713, "train/mean_reward/goal_8": -1.584921572553484, "train/final_reward/goal_8": -1.8911457061767578, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.2532413005828857, "train/max_reward/goal_9": -0.8981073498725891, "train/mean_reward/goal_9": -1.5639927748002505, "train/final_reward/goal_9": -2.029609203338623, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.1018927097320557, "train/max_reward/goal_10": -1.1097983121871948, "train/mean_reward/goal_10": -1.5897000526127063, "train/final_reward/goal_10": -1.6259771585464478, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1253821849823, "train/max_reward/goal_11": -2.459944009780884, "train/mean_reward/goal_11": -2.8793630098041736, "train/final_reward/goal_11": -2.6835761070251465}
{"step": 0, "dataset_size": 1800.0, "train/return": -130.24297749996185, "train/length": 75.0, "train/episodes": 24.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 1.0, "train/mean_success/goal_0": 0.02631578947368421, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.7105281352996826, "train/max_reward/goal_0": -0.4403931796550751, "train/mean_reward/goal_0": -2.379198790772965, "train/final_reward/goal_0": -2.1884899139404297, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1413469314575195, "train/max_reward/goal_1": -2.224144697189331, "train/mean_reward/goal_1": -2.838350004271457, "train/final_reward/goal_1": -2.329594850540161, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.7105281352996826, "train/max_reward/goal_2": -1.1639716625213623, "train/mean_reward/goal_2": -2.4073177481952466, "train/final_reward/goal_2": -2.1884899139404297, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -3.05234432220459, "train/max_reward/goal_3": -0.9576641321182251, "train/mean_reward/goal_3": -1.7560235826592696, "train/final_reward/goal_3": -1.756605863571167, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.108173131942749, "train/max_reward/goal_4": -1.7609134912490845, "train/mean_reward/goal_4": -2.5076808066744554, "train/final_reward/goal_4": -1.760970950126648, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -3.132948637008667, "train/max_reward/goal_5": -1.0995949506759644, "train/mean_reward/goal_5": -2.026722241389124, "train/final_reward/goal_5": -1.0995949506759644, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.602344274520874, "train/max_reward/goal_6": -0.8873983025550842, "train/mean_reward/goal_6": -1.495198288246205, "train/final_reward/goal_6": -1.5366058349609375, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.7105281352996826, "train/max_reward/goal_7": -1.1639716625213623, "train/mean_reward/goal_7": -2.4085019607292977, "train/final_reward/goal_7": -2.1884899139404297, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.2263872623443604, "train/max_reward/goal_8": -0.7971010804176331, "train/mean_reward/goal_8": -1.6580367213801335, "train/final_reward/goal_8": -2.0609710216522217, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -3.05234432220459, "train/max_reward/goal_9": -0.9818508625030518, "train/mean_reward/goal_9": -1.750472710320824, "train/final_reward/goal_9": -1.0566058158874512, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.2404050827026367, "train/max_reward/goal_10": -1.239687204360962, "train/mean_reward/goal_10": -1.6651336582083451, "train/final_reward/goal_10": -2.2404050827026367, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1413469314575195, "train/max_reward/goal_11": -2.224144697189331, "train/mean_reward/goal_11": -2.838350004271457, "train/final_reward/goal_11": -2.329594850540161}
{"step": 0, "dataset_size": 1875.0, "train/return": -126.2168804705143, "train/length": 75.0, "train/episodes": 25.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.1368980407714844, "train/max_reward/goal_0": -1.7464464902877808, "train/mean_reward/goal_0": -2.5374553172211898, "train/final_reward/goal_0": -3.024263620376587, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.07894736842105263, "train/final_success/goal_1": 1.0, "train/min_reward/goal_1": -3.0209128856658936, "train/max_reward/goal_1": -0.34781813621520996, "train/mean_reward/goal_1": -2.0392299082718397, "train/final_reward/goal_1": -0.34781813621520996, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.1368980407714844, "train/max_reward/goal_2": -1.7464464902877808, "train/mean_reward/goal_2": -2.5414303400014577, "train/final_reward/goal_2": -3.024263620376587, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 1.0, "train/mean_success/goal_3": 0.10526315789473684, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.332395076751709, "train/max_reward/goal_3": -0.41591963171958923, "train/mean_reward/goal_3": -1.3923464860571058, "train/final_reward/goal_3": -1.881801962852478, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 1.0, "train/mean_success/goal_4": 0.039473684210526314, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.633864402770996, "train/max_reward/goal_4": -0.593478262424469, "train/mean_reward/goal_4": -1.9722732156515121, "train/final_reward/goal_4": -2.1818020343780518, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 1.0, "train/mean_success/goal_5": 0.02631578947368421, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -1.992395043373108, "train/max_reward/goal_5": -0.45406994223594666, "train/mean_reward/goal_5": -1.53240838529248, "train/final_reward/goal_5": -1.4118019342422485, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.7823948860168457, "train/max_reward/goal_6": -0.7039541006088257, "train/mean_reward/goal_6": -1.6906970260958922, "train/final_reward/goal_6": -1.9042637348175049, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.132395029067993, "train/max_reward/goal_7": -1.4697402715682983, "train/mean_reward/goal_7": -2.4318694456627497, "train/final_reward/goal_7": -2.2542636394500732, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.0655596256256104, "train/max_reward/goal_8": -1.3068585395812988, "train/mean_reward/goal_8": -2.1495208238300525, "train/final_reward/goal_8": -2.6289215087890625, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 1.0, "train/mean_success/goal_9": 0.02631578947368421, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.332395076751709, "train/max_reward/goal_9": -0.4309878647327423, "train/mean_reward/goal_9": -1.6711885062487501, "train/final_reward/goal_9": -1.8118019104003906, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.128788948059082, "train/max_reward/goal_10": -1.175866961479187, "train/mean_reward/goal_10": -2.21385521167203, "train/final_reward/goal_10": -1.8289215564727783, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.0209128856658936, "train/max_reward/goal_11": -1.0269651412963867, "train/mean_reward/goal_11": -2.1565082528089223, "train/final_reward/goal_11": -1.881801962852478}
{"step": 0, "dataset_size": 1950.0, "train/return": -152.75038254261017, "train/length": 75.0, "train/episodes": 26.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.1380183696746826, "train/max_reward/goal_0": -1.7201696634292603, "train/mean_reward/goal_0": -2.618906962244134, "train/final_reward/goal_0": -3.1169676780700684, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.02631578947368421, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.7077863216400146, "train/max_reward/goal_1": -0.530556857585907, "train/mean_reward/goal_1": -2.0256629288196564, "train/final_reward/goal_1": -2.691117525100708, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.1380183696746826, "train/max_reward/goal_2": -1.6566623449325562, "train/mean_reward/goal_2": -2.6168620100146844, "train/final_reward/goal_2": -3.1169676780700684, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -3.056523084640503, "train/max_reward/goal_3": -0.8614770174026489, "train/mean_reward/goal_3": -1.8780848799567473, "train/final_reward/goal_3": -1.5962177515029907, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.6417899131774902, "train/max_reward/goal_4": -0.7574844360351562, "train/mean_reward/goal_4": -1.6694245205113762, "train/final_reward/goal_4": -2.2432940006256104, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.7165229320526123, "train/max_reward/goal_5": -0.8330159187316895, "train/mean_reward/goal_5": -1.6462508314534237, "train/final_reward/goal_5": -1.3511173725128174, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -3.1086158752441406, "train/max_reward/goal_6": -0.9314770102500916, "train/mean_reward/goal_6": -2.2440069843279686, "train/final_reward/goal_6": -2.046217679977417, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.1391732692718506, "train/max_reward/goal_7": -2.055689811706543, "train/mean_reward/goal_7": -2.6565607252873873, "train/final_reward/goal_7": -2.691117525100708, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.1095523834228516, "train/max_reward/goal_8": -1.2488459348678589, "train/mean_reward/goal_8": -2.232000481141241, "train/final_reward/goal_8": -2.4869675636291504, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -3.056523084640503, "train/max_reward/goal_9": -1.0627697706222534, "train/mean_reward/goal_9": -1.9401303608166545, "train/final_reward/goal_9": -1.5962177515029907, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 1.0, "train/mean_success/goal_10": 0.02631578947368421, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.1148557662963867, "train/max_reward/goal_10": -0.5586158633232117, "train/mean_reward/goal_10": -1.6675925960666256, "train/final_reward/goal_10": -1.6911174058914185, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.7077863216400146, "train/max_reward/goal_11": -0.7000797986984253, "train/mean_reward/goal_11": -2.0374672350130583, "train/final_reward/goal_11": -2.691117525100708}
{"step": 0, "dataset_size": 2025.0, "train/return": -204.1136314868927, "train/length": 75.0, "train/episodes": 27.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.6749188899993896, "train/max_reward/goal_0": -1.6256986856460571, "train/mean_reward/goal_0": -2.2446520767713847, "train/final_reward/goal_0": -2.5037484169006348, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1407828330993652, "train/max_reward/goal_1": -1.6227542161941528, "train/mean_reward/goal_1": -2.7222080920871936, "train/final_reward/goal_1": -3.1166906356811523, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.6749188899993896, "train/max_reward/goal_2": -1.6256986856460571, "train/mean_reward/goal_2": -2.2477864450530003, "train/final_reward/goal_2": -2.5037484169006348, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.0065550804138184, "train/max_reward/goal_3": -1.0918564796447754, "train/mean_reward/goal_3": -1.5429433474415226, "train/final_reward/goal_3": -1.546690583229065, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.90655517578125, "train/max_reward/goal_4": -0.792716920375824, "train/mean_reward/goal_4": -2.2024668070830797, "train/final_reward/goal_4": -2.446690559387207, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.34655499458313, "train/max_reward/goal_5": -0.7340287566184998, "train/mean_reward/goal_5": -1.6527838142294633, "train/final_reward/goal_5": -1.886690616607666, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.6443023681640625, "train/max_reward/goal_6": -0.7716071605682373, "train/mean_reward/goal_6": -1.347265395678972, "train/final_reward/goal_6": -1.0966905355453491, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.6749188899993896, "train/max_reward/goal_7": -1.1827094554901123, "train/mean_reward/goal_7": -2.2088398055026404, "train/final_reward/goal_7": -2.5037484169006348, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.05263157894736842, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.7321386337280273, "train/max_reward/goal_8": -0.3395316004753113, "train/mean_reward/goal_8": -1.785832558023302, "train/final_reward/goal_8": -1.4520423412322998, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.0065550804138184, "train/max_reward/goal_9": -0.7740287780761719, "train/mean_reward/goal_9": -1.4405291174587451, "train/final_reward/goal_9": -1.546690583229065, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.1352434158325195, "train/max_reward/goal_10": -1.1216639280319214, "train/mean_reward/goal_10": -1.8446749793855768, "train/final_reward/goal_10": -1.5037484169006348, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1407828330993652, "train/max_reward/goal_11": -1.2041292190551758, "train/mean_reward/goal_11": -2.7032622553800283, "train/final_reward/goal_11": -3.1166906356811523}
{"step": 0, "dataset_size": 2100.0, "train/return": -123.15613889694214, "train/length": 75.0, "train/episodes": 28.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.1407902240753174, "train/max_reward/goal_0": -2.4700729846954346, "train/mean_reward/goal_0": -2.9322452702020345, "train/final_reward/goal_0": -3.003941774368286, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.18421052631578946, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.7123210430145264, "train/max_reward/goal_1": -0.282150000333786, "train/mean_reward/goal_1": -1.5739344201589887, "train/final_reward/goal_1": -1.1110594272613525, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.1407902240753174, "train/max_reward/goal_2": -2.4700729846954346, "train/mean_reward/goal_2": -2.9322452702020345, "train/final_reward/goal_2": -3.003941774368286, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.243112325668335, "train/max_reward/goal_3": -1.410564661026001, "train/mean_reward/goal_3": -1.764381159293024, "train/final_reward/goal_3": -1.7092435359954834, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.282414436340332, "train/max_reward/goal_4": -0.7779659032821655, "train/mean_reward/goal_4": -1.6268774271011353, "train/final_reward/goal_4": -1.4953287839889526, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -1.9031124114990234, "train/max_reward/goal_5": -1.0943137407302856, "train/mean_reward/goal_5": -1.4166144665918852, "train/final_reward/goal_5": -1.3692436218261719, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.693112373352051, "train/max_reward/goal_6": -1.6421136856079102, "train/mean_reward/goal_6": -2.095081578744085, "train/final_reward/goal_6": -2.159243583679199, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.0431125164031982, "train/max_reward/goal_7": -1.992113709449768, "train/mean_reward/goal_7": -2.4924389516052448, "train/final_reward/goal_7": -2.5092434883117676, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.8910715579986572, "train/max_reward/goal_8": -1.896204948425293, "train/mean_reward/goal_8": -2.4417542642668675, "train/final_reward/goal_8": -2.373941659927368, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.243112325668335, "train/max_reward/goal_9": -1.3406717777252197, "train/mean_reward/goal_9": -1.740838596695348, "train/final_reward/goal_9": -1.7092435359954834, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.091071605682373, "train/max_reward/goal_10": -1.0962049961090088, "train/mean_reward/goal_10": -1.6443604277937036, "train/final_reward/goal_10": -1.573941707611084, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.7123210430145264, "train/max_reward/goal_11": -0.8590226173400879, "train/mean_reward/goal_11": -1.8298005885199498, "train/final_reward/goal_11": -1.1953288316726685}
{"step": 0, "dataset_size": 2175.0, "train/return": -123.70995485782623, "train/length": 75.0, "train/episodes": 29.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.1336722373962402, "train/max_reward/goal_0": -2.071079969406128, "train/mean_reward/goal_0": -2.8334389987744784, "train/final_reward/goal_0": -3.04083514213562, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.07894736842105263, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.6913373470306396, "train/max_reward/goal_1": -0.22851519286632538, "train/mean_reward/goal_1": -1.8594288576982523, "train/final_reward/goal_1": -2.613784074783325, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.1336722373962402, "train/max_reward/goal_2": -2.071079969406128, "train/mean_reward/goal_2": -2.8334389987744784, "train/final_reward/goal_2": -3.04083514213562, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.8098199367523193, "train/max_reward/goal_3": -1.5253753662109375, "train/mean_reward/goal_3": -1.88409665540645, "train/final_reward/goal_3": -1.6723501682281494, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.6302146911621094, "train/max_reward/goal_4": -1.0387769937515259, "train/mean_reward/goal_4": -1.647290891722629, "train/final_reward/goal_4": -2.5602900981903076, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.469820022583008, "train/max_reward/goal_5": -1.1350610256195068, "train/mean_reward/goal_5": -1.5783840010040684, "train/final_reward/goal_5": -1.9002901315689087, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -3.0921053886413574, "train/max_reward/goal_6": -1.6412326097488403, "train/mean_reward/goal_6": -2.260663440352992, "train/final_reward/goal_6": -2.1223502159118652, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.0982420444488525, "train/max_reward/goal_7": -2.0206210613250732, "train/mean_reward/goal_7": -2.629821438538401, "train/final_reward/goal_7": -2.613784074783325, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.8919527530670166, "train/max_reward/goal_8": -1.635960340499878, "train/mean_reward/goal_8": -2.2997218166526996, "train/final_reward/goal_8": -2.4108352661132812, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.8098199367523193, "train/max_reward/goal_9": -1.4536703824996948, "train/mean_reward/goal_9": -1.8909656358392615, "train/final_reward/goal_9": -1.9602901935577393, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.1302146911621094, "train/max_reward/goal_10": -0.835960328578949, "train/mean_reward/goal_10": -1.5410719921714382, "train/final_reward/goal_10": -2.0602900981903076, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.6913373470306396, "train/max_reward/goal_11": -0.8683449029922485, "train/mean_reward/goal_11": -1.9552534222602844, "train/final_reward/goal_11": -2.613784074783325}
{"step": 0, "dataset_size": 2250.0, "train/return": -172.72268402576447, "train/length": 75.0, "train/episodes": 30.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.1248772144317627, "train/max_reward/goal_0": -1.4539470672607422, "train/mean_reward/goal_0": -2.59111844238482, "train/final_reward/goal_0": -2.5458662509918213, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1020305156707764, "train/max_reward/goal_1": -0.8844066858291626, "train/mean_reward/goal_1": -2.3025699304906944, "train/final_reward/goal_1": -1.7522952556610107, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.1248772144317627, "train/max_reward/goal_2": -1.6496069431304932, "train/mean_reward/goal_2": -2.6068580919190456, "train/final_reward/goal_2": -2.5458662509918213, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 1.0, "train/mean_success/goal_3": 0.10526315789473684, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.2704789638519287, "train/max_reward/goal_3": -0.1539740115404129, "train/mean_reward/goal_3": -1.4450631625950336, "train/final_reward/goal_3": -2.1673190593719482, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 1.0, "train/mean_success/goal_4": 0.013157894736842105, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.599383592605591, "train/max_reward/goal_4": -0.5900216698646545, "train/mean_reward/goal_4": -1.7496029224834944, "train/final_reward/goal_4": -1.4947177171707153, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -1.9778820276260376, "train/max_reward/goal_5": -0.7566157579421997, "train/mean_reward/goal_5": -1.415657350891515, "train/final_reward/goal_5": -1.8273190259933472, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 1.0, "train/mean_success/goal_6": 0.02631578947368421, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.7204790115356445, "train/max_reward/goal_6": -0.6378539800643921, "train/mean_reward/goal_6": -1.6048469857165688, "train/final_reward/goal_6": -2.617318868637085, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.070478916168213, "train/max_reward/goal_7": -1.542812466621399, "train/mean_reward/goal_7": -2.509247644951469, "train/final_reward/goal_7": -2.9673190116882324, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.1318817138671875, "train/max_reward/goal_8": -0.9983713626861572, "train/mean_reward/goal_8": -2.1512440976343656, "train/final_reward/goal_8": -2.052295207977295, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.2704789638519287, "train/max_reward/goal_9": -0.7573931217193604, "train/mean_reward/goal_9": -1.5967815337996734, "train/final_reward/goal_9": -2.1673190593719482, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.1332669258117676, "train/max_reward/goal_10": -1.0845024585723877, "train/mean_reward/goal_10": -2.1707077842009697, "train/final_reward/goal_10": -1.1158663034439087, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1020305156707764, "train/max_reward/goal_11": -0.8844066858291626, "train/mean_reward/goal_11": -2.304269359300011, "train/final_reward/goal_11": -1.5870949029922485}
{"step": 0, "dataset_size": 2325.0, "train/return": -127.53698617219925, "train/length": 75.0, "train/episodes": 31.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -3.14158296585083, "train/max_reward/goal_0": -1.968261957168579, "train/mean_reward/goal_0": -2.7595241791323613, "train/final_reward/goal_0": -3.0287458896636963, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 1.0, "train/mean_success/goal_1": 0.013157894736842105, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -2.7019569873809814, "train/max_reward/goal_1": -0.40370112657546997, "train/mean_reward/goal_1": -1.726419742170133, "train/final_reward/goal_1": -2.55643630027771, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -3.14158296585083, "train/max_reward/goal_2": -1.968261957168579, "train/mean_reward/goal_2": -2.7595241791323613, "train/final_reward/goal_2": -3.0287458896636963, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 1.0, "train/mean_success/goal_3": 0.09210526315789473, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.2677526473999023, "train/max_reward/goal_3": -0.4785363972187042, "train/mean_reward/goal_3": -1.5911739668563794, "train/final_reward/goal_3": -1.633445382118225, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.378577709197998, "train/max_reward/goal_4": -0.9396237134933472, "train/mean_reward/goal_4": -1.5693435363079373, "train/final_reward/goal_4": -1.9334453344345093, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -1.9277526140213013, "train/max_reward/goal_5": -0.7377842664718628, "train/mean_reward/goal_5": -1.3977844173970975, "train/final_reward/goal_5": -1.4620834589004517, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.717752695083618, "train/max_reward/goal_6": -0.9236442446708679, "train/mean_reward/goal_6": -1.9565710346949727, "train/final_reward/goal_6": -1.9087457656860352, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -3.0677525997161865, "train/max_reward/goal_7": -1.9166580438613892, "train/mean_reward/goal_7": -2.493112324099792, "train/final_reward/goal_7": -2.55643630027771, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -3.0968642234802246, "train/max_reward/goal_8": -1.9655603170394897, "train/mean_reward/goal_8": -2.4122940490120337, "train/final_reward/goal_8": -2.6244394779205322, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.2677526473999023, "train/max_reward/goal_9": -0.8847180604934692, "train/mean_reward/goal_9": -1.6929030316440683, "train/final_reward/goal_9": -1.8620834350585938, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.132524251937866, "train/max_reward/goal_10": -1.0154327154159546, "train/mean_reward/goal_10": -1.8576188510970066, "train/final_reward/goal_10": -1.824439525604248, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -2.7019569873809814, "train/max_reward/goal_11": -0.8470720648765564, "train/mean_reward/goal_11": -1.7781019767648296, "train/final_reward/goal_11": -2.55643630027771}
{"step": 0, "dataset_size": 2400.0, "train/return": -128.20274662971497, "train/length": 75.0, "train/episodes": 32.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.6700868606567383, "train/max_reward/goal_0": -1.1691547632217407, "train/mean_reward/goal_0": -2.4415591782645176, "train/final_reward/goal_0": -2.485323667526245, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1408629417419434, "train/max_reward/goal_1": -2.0583877563476562, "train/mean_reward/goal_1": -2.750460947814741, "train/final_reward/goal_1": -2.9654507637023926, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.6700868606567383, "train/max_reward/goal_2": -1.1691547632217407, "train/mean_reward/goal_2": -2.4386549764557888, "train/final_reward/goal_2": -2.485323667526245, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -1.9319162368774414, "train/max_reward/goal_3": -0.707659900188446, "train/mean_reward/goal_3": -1.4393194858965122, "train/final_reward/goal_3": -1.3954507112503052, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -2.831916332244873, "train/max_reward/goal_4": -1.3883877992630005, "train/mean_reward/goal_4": -2.2807109308870217, "train/final_reward/goal_4": -2.2954506874084473, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.271916389465332, "train/max_reward/goal_5": -0.8283877968788147, "train/mean_reward/goal_5": -1.6898328058029477, "train/final_reward/goal_5": -1.7354507446289062, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 1.0, "train/mean_success/goal_6": 0.013157894736842105, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.8517240285873413, "train/max_reward/goal_6": -0.4514370560646057, "train/mean_reward/goal_6": -1.3791300889692808, "train/final_reward/goal_6": -1.534359097480774, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.6700868606567383, "train/max_reward/goal_7": -1.1691547632217407, "train/mean_reward/goal_7": -2.4386549764557888, "train/final_reward/goal_7": -2.485323667526245, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 1.0, "train/mean_success/goal_8": 0.02631578947368421, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.253363847732544, "train/max_reward/goal_8": -0.580646812915802, "train/mean_reward/goal_8": -1.7103666396517503, "train/final_reward/goal_8": -2.054359197616577, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 1.0, "train/mean_success/goal_9": 0.02631578947368421, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.0517239570617676, "train/max_reward/goal_9": -0.488387793302536, "train/mean_reward/goal_9": -1.6195386118794743, "train/final_reward/goal_9": -1.4696577787399292, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -3.053363800048828, "train/max_reward/goal_10": -1.2577940225601196, "train/mean_reward/goal_10": -2.0596790862710854, "train/final_reward/goal_10": -1.6045492887496948, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1408629417419434, "train/max_reward/goal_11": -2.0583877563476562, "train/mean_reward/goal_11": -2.750460947814741, "train/final_reward/goal_11": -2.9654507637023926}
{"step": 0, "dataset_size": 2475.0, "train/return": -130.02028799057007, "train/length": 75.0, "train/episodes": 33.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.6947762966156006, "train/max_reward/goal_0": -1.2587525844573975, "train/mean_reward/goal_0": -2.420717368000432, "train/final_reward/goal_0": -2.5089173316955566, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1413357257843018, "train/max_reward/goal_1": -2.173363208770752, "train/mean_reward/goal_1": -2.9120248901216605, "train/final_reward/goal_1": -3.129923105239868, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.6947762966156006, "train/max_reward/goal_2": -1.2587525844573975, "train/mean_reward/goal_2": -2.413877901278044, "train/final_reward/goal_2": -2.5089173316955566, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -2.222050189971924, "train/max_reward/goal_3": -1.059322714805603, "train/mean_reward/goal_3": -1.6120473068011434, "train/final_reward/goal_3": -1.5832622051239014, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.1220500469207764, "train/max_reward/goal_4": -1.5033631324768066, "train/mean_reward/goal_4": -2.404122016931835, "train/final_reward/goal_4": -2.507390022277832, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -2.5620501041412354, "train/max_reward/goal_5": -0.9489017128944397, "train/mean_reward/goal_5": -1.829462269419118, "train/final_reward/goal_5": -1.9232622385025024, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -1.7976804971694946, "train/max_reward/goal_6": -0.8722553253173828, "train/mean_reward/goal_6": -1.4481710430822874, "train/final_reward/goal_6": -1.7073899507522583, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.6947762966156006, "train/max_reward/goal_7": -1.2587525844573975, "train/mean_reward/goal_7": -2.413877901278044, "train/final_reward/goal_7": -2.5089173316955566, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.1609182357788086, "train/max_reward/goal_8": -0.9368808269500732, "train/mean_reward/goal_8": -1.7252669475580518, "train/final_reward/goal_8": -2.077465772628784, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -2.222050189971924, "train/max_reward/goal_9": -0.8347727656364441, "train/mean_reward/goal_9": -1.616635381391174, "train/final_reward/goal_9": -1.9073898792266846, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.396636962890625, "train/max_reward/goal_10": -1.2223094701766968, "train/mean_reward/goal_10": -1.7461137614752118, "train/final_reward/goal_10": -2.007390022277832, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1413357257843018, "train/max_reward/goal_11": -2.173363208770752, "train/mean_reward/goal_11": -2.9120248901216605, "train/final_reward/goal_11": -3.129923105239868}
{"step": 0, "dataset_size": 2550.0, "train/return": -120.52783513069153, "train/length": 75.0, "train/episodes": 34.0, "train/min_success/goal_0": 0.0, "train/max_success/goal_0": 0.0, "train/mean_success/goal_0": 0.0, "train/final_success/goal_0": 0.0, "train/min_reward/goal_0": -2.723198413848877, "train/max_reward/goal_0": -1.9234106540679932, "train/mean_reward/goal_0": -2.4127106729306673, "train/final_reward/goal_0": -2.3410212993621826, "train/min_success/goal_1": 0.0, "train/max_success/goal_1": 0.0, "train/mean_success/goal_1": 0.0, "train/final_success/goal_1": 0.0, "train/min_reward/goal_1": -3.1407055854797363, "train/max_reward/goal_1": -1.9234106540679932, "train/mean_reward/goal_1": -2.8166384006801404, "train/final_reward/goal_1": -2.982332229614258, "train/min_success/goal_2": 0.0, "train/max_success/goal_2": 0.0, "train/mean_success/goal_2": 0.0, "train/final_success/goal_2": 0.0, "train/min_reward/goal_2": -2.723198413848877, "train/max_reward/goal_2": -1.9277739524841309, "train/mean_reward/goal_2": -2.4127680847519324, "train/final_reward/goal_2": -2.3410212993621826, "train/min_success/goal_3": 0.0, "train/max_success/goal_3": 0.0, "train/mean_success/goal_3": 0.0, "train/final_success/goal_3": 0.0, "train/min_reward/goal_3": -3.127955198287964, "train/max_reward/goal_3": -1.360105037689209, "train/mean_reward/goal_3": -1.9575186120836359, "train/final_reward/goal_3": -1.7308529615402222, "train/min_success/goal_4": 0.0, "train/max_success/goal_4": 0.0, "train/mean_success/goal_4": 0.0, "train/final_success/goal_4": 0.0, "train/min_reward/goal_4": -3.1401407718658447, "train/max_reward/goal_4": -2.1563327312469482, "train/mean_reward/goal_4": -2.564496774422495, "train/final_reward/goal_4": -2.6308529376983643, "train/min_success/goal_5": 0.0, "train/max_success/goal_5": 0.0, "train/mean_success/goal_5": 0.0, "train/final_success/goal_5": 0.0, "train/min_reward/goal_5": -3.130019187927246, "train/max_reward/goal_5": -1.5480117797851562, "train/mean_reward/goal_5": -2.2156799749324194, "train/final_reward/goal_5": -2.0708529949188232, "train/min_success/goal_6": 0.0, "train/max_success/goal_6": 0.0, "train/mean_success/goal_6": 0.0, "train/final_success/goal_6": 0.0, "train/min_reward/goal_6": -2.677955150604248, "train/max_reward/goal_6": -1.0984175205230713, "train/mean_reward/goal_6": -1.7134223878383636, "train/final_reward/goal_6": -1.280853033065796, "train/min_success/goal_7": 0.0, "train/max_success/goal_7": 0.0, "train/mean_success/goal_7": 0.0, "train/final_success/goal_7": 0.0, "train/min_reward/goal_7": -2.723198413848877, "train/max_reward/goal_7": -1.9516191482543945, "train/mean_reward/goal_7": -2.415558454237486, "train/final_reward/goal_7": -2.3410212993621826, "train/min_success/goal_8": 0.0, "train/max_success/goal_8": 0.0, "train/mean_success/goal_8": 0.0, "train/final_success/goal_8": 0.0, "train/min_reward/goal_8": -2.1836845874786377, "train/max_reward/goal_8": -0.8212194442749023, "train/mean_reward/goal_8": -1.743680750853137, "train/final_reward/goal_8": -1.1817376613616943, "train/min_success/goal_9": 0.0, "train/max_success/goal_9": 0.0, "train/mean_success/goal_9": 0.0, "train/final_success/goal_9": 0.0, "train/min_reward/goal_9": -3.127955198287964, "train/max_reward/goal_9": -1.2563327550888062, "train/mean_reward/goal_9": -2.0002565666248926, "train/final_reward/goal_9": -1.7410212755203247, "train/min_success/goal_10": 0.0, "train/max_success/goal_10": 0.0, "train/mean_success/goal_10": 0.0, "train/final_success/goal_10": 0.0, "train/min_reward/goal_10": -2.1108808517456055, "train/max_reward/goal_10": -1.0342596769332886, "train/mean_reward/goal_10": -1.6047005025964034, "train/final_reward/goal_10": -1.3410212993621826, "train/min_success/goal_11": 0.0, "train/max_success/goal_11": 0.0, "train/mean_success/goal_11": 0.0, "train/final_success/goal_11": 0.0, "train/min_reward/goal_11": -3.1407055854797363, "train/max_reward/goal_11": -1.9234106540679932, "train/mean_reward/goal_11": -2.8166384006801404, "train/final_reward/goal_11": -2.982332229614258}
{"step": 0, "eval/return": -197.8196268081665, "eval/length": 75.0, "eval/episodes": 1.0, "eval/min_success/goal_0": 0.0, "eval/max_success/goal_0": 0.0, "eval/mean_success/goal_0": 0.0, "eval/final_success/goal_0": 0.0, "eval/min_reward/goal_0": -3.139861822128296, "eval/max_reward/goal_0": -1.5378283262252808, "eval/mean_reward/goal_0": -2.62312440966305, "eval/final_reward/goal_0": -2.230543613433838}
